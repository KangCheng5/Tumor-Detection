{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor Detection (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped to sampled_images\n"
     ]
    }
   ],
   "source": [
    "zip_path = \"train take out 1.zip\"\n",
    "extract_folder = \"sampled_images\"\n",
    "\n",
    "# Create folder and unzip\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Unzipped to {extract_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sampled images: 1000\n"
     ]
    }
   ],
   "source": [
    "sampled_filenames = os.listdir('train take out 1')\n",
    "# Remove file extensions from sampled image names\n",
    "sampled_ids = [os.path.splitext(f)[0] for f in sampled_filenames]\n",
    "print(f\"Total sampled images: {len(sampled_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels matched: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load the full labels\n",
    "labels_df = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "# Optional: strip whitespace from filenames\n",
    "labels_df['id'] = labels_df['id'].str.strip()\n",
    "\n",
    "# Filter for only sampled images\n",
    "filtered_labels = labels_df[labels_df['id'].isin(sampled_ids)]\n",
    "\n",
    "print(f\"Labels matched: {len(filtered_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sampled_labels.csv!\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered labels\n",
    "filtered_labels.to_csv(\"sampled_labels.csv\", index=False)\n",
    "print(\"Saved sampled_labels.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    596\n",
       "1    404\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sampled_labels.csv')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         id  label  \\\n",
      "0  c363267f3311039b685f0fec2311060e5f7f93f6      0   \n",
      "1  00b25ec6689474e5d5a471e50094ccf529e4173d      0   \n",
      "2  573fbded852b0ba1fb7361247814ccf3cff73f38      0   \n",
      "3  ffe632addae0b0846dcc4f60d715cecefdca0983      1   \n",
      "4  ffcacb05e57c4a333fccb2744298b9275a9f79c4      1   \n",
      "\n",
      "                                          image_path  \n",
      "0  train take out 1/c363267f3311039b685f0fec23110...  \n",
      "1  train take out 1/00b25ec6689474e5d5a471e50094c...  \n",
      "2  train take out 1/573fbded852b0ba1fb7361247814c...  \n",
      "3  train take out 1/ffe632addae0b0846dcc4f60d715c...  \n",
      "4  train take out 1/ffcacb05e57c4a333fccb2744298b...  \n"
     ]
    }
   ],
   "source": [
    "# Add the .tif extension if needed\n",
    "df['filename'] = df['id'] + \".tif\"\n",
    "\n",
    "# Add the full image path\n",
    "df['image_path'] = df['filename'].apply(lambda x: os.path.join(\"train take out 1\", x))\n",
    "\n",
    "# Check it worked\n",
    "print(df[['id', 'label' if 'label' in df.columns else df.columns[-1], 'image_path']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Data Generators (TensorFlow/Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 validated image filenames belonging to 2 classes.\n",
      "Found 200 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "label_col = 'label'  # change if yours is different (e.g. 'diagnosis')\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image_path',\n",
    "    y_col=label_col,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',   # or 'categorical' if more than 2 classes\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image_path',\n",
    "    y_col=label_col,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define and Compile a Simple CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11944000  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,963,457\n",
      "Trainable params: 11,963,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models \n",
    "\n",
    "model = models.Sequential([ \n",
    "    layers.Input(shape=(224, 224, 3)), \n",
    "    layers.Conv2D(32, (3, 3), activation='relu'), \n",
    "    layers.MaxPooling2D(), layers.Conv2D(64, (3, 3), \n",
    "    activation='relu'), \n",
    "    layers.MaxPooling2D(), \n",
    "    layers.Flatten(), \n",
    "    layers.Dense(64, activation='relu'), \n",
    "    layers.Dense(1, activation='sigmoid') # binary output \n",
    "    ]) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 25 steps, validate for 7 steps\n",
      "Epoch 1/3\n",
      "25/25 [==============================] - 223s 9s/step - loss: 0.1712 - accuracy: 0.9575 - val_loss: 1.6007 - val_accuracy: 0.6700\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 224s 9s/step - loss: 0.2011 - accuracy: 0.9400 - val_loss: 0.8892 - val_accuracy: 0.6150\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 225s 9s/step - loss: 0.0715 - accuracy: 0.9850 - val_loss: 1.5226 - val_accuracy: 0.6550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( train_gen, validation_data=val_gen, epochs=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "7/7 [==============================] - 15s 2s/step - loss: 1.5226 - accuracy: 0.6550\n",
      "Validation Accuracy: 0.6550\n"
     ]
    }
   ],
   "source": [
    "# Evaluate \n",
    "loss, acc = model.evaluate(val_gen) \n",
    "print(f\"Validation Accuracy: {acc:.4f}\") \n",
    "# Save model \n",
    "model.save(\"tumor_cnn_model.h5\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
